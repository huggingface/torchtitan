[1mdiff --git a/tt_run.log.filtered b/hf_run.log.filtered[m
[1mindex 9726db6..84b6138 100644[m
[1m--- a/tt_run.log.filtered[m
[1m+++ b/hf_run.log.filtered[m
[36m@@ -1,85 +1,153 @@[m
+ echo [31m'##############################################'[m
[31m##############################################[m[32m'#######################################################'[m
[32m#######################################################[m
+ echo '### Running TorchTitan [31m(native)[m[32mwith HF backend[m training ###'
### Running TorchTitan [31m(native)[m[32mwith HF backend[m training ###
+ echo [31m'##############################################'[m
[31m##############################################[m[32m'#######################################################'[m
[32m#######################################################[m
+ [31mTT_CONFIG=/fsx/ferdinandmom/ferdinand-hf/huggingface/torchtitan/torchtitan/experiments/transformers_backend/configs/debug_1_gpu_tt.toml[m[32mHF_CONFIG=/fsx/ferdinandmom/ferdinand-hf/huggingface/torchtitan/torchtitan/experiments/transformers_backend/configs/debug_1_gpu_hf.toml[m
+ [31mCUDA_VISIBLE_DEVICES=0[m[32mCUDA_VISIBLE_DEVICES=1[m
+ torchrun ... --master_port=XXXX --rdzv_backend c10d --rdzv_endpoint=localhost:XXXX --local-ranks-filter 0 --role rank --tee 3 -m torchtitan.train --job.config_file [31m/fsx/ferdinandmom/ferdinand-hf/huggingface/torchtitan/torchtitan/experiments/transformers_backend/configs/debug_1_gpu_tt.toml[m[32m/fsx/ferdinandmom/ferdinand-hf/huggingface/torchtitan/torchtitan/experiments/transformers_backend/configs/debug_1_gpu_hf.toml[m --training.seed 42 --training.deterministic --model.name [31mdeepseek_v3[m[32mdeepseek-ai/DeepSeek-V3[m
[rank0]:/fsx/ferdinandmom/ferdinand-hf/huggingface/torchtitan/transformers/src/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.[m
[rank0]:  warnings.warn([m
[rank0]:[titan] TIMESTAMP - root - [32mWARNING - tokenizer_path is deprecated, use model.hf_assets_path instead. Setting hf_assets_path to tokenizer_path temporarily.[m
[32m[rank0]:[titan] TIMESTAMP - root -[m INFO - Starting job: [32mHF[m Llama 3 debug training
[rank0]:[titan] TIMESTAMP - root - WARNING - ENV[TORCH_NCCL_ASYNC_ERROR_HANDLING] = 1 will be overridden to 3 based on job config[m
[rank0]:[titan] TIMESTAMP - root - INFO - Building 0-D device mesh with [], [][m
[rank0]:[titan] TIMESTAMP - root - INFO - [GC] Initial GC collection 0.00 seconds[m
[rank0]:[titan] TIMESTAMP - root - INFO - Deterministic algorithm enabled (expect perf degradation).[m
[rank0]:[titan] TIMESTAMP - root - INFO - Loading tokenizer from tokenizer.json[m
[rank0]:[titan] TIMESTAMP - root - INFO - Preparing c4_test dataset from /fsx/ferdinandmom/ferdinand-hf/huggingface/torchtitan/tests/assets/c4_test[m
[rank0]:[titan] TIMESTAMP - root - INFO - Building [31mdeepseek_v3[m[32mdeepseek-ai/DeepSeek-V3[m debugmodel with [31mDeepSeekV3ModelArgs(_enforced='This field is used to enforce all fields have defaults.', max_batch_size=8, max_seq_len=2048, vocab_size=2000, dim=256, inter_dim=1024, moe_inter_dim=256, n_layers=2, n_dense_layers=1, n_heads=16, norm_eps=1e-05, moe_args=MoEArgs(num_experts=8,[m[32mHFTransformerModelArgs([m
[32m[rank0]:attn_implementation='sdpa'[m
[32m[rank0]:attn_mask_type='causal'[m
[32m[rank0]:beta_fast=None[m
[32m[rank0]:beta_slow=None[m
[32m[rank0]:depth_init=True[m
[32m[rank0]:dim=256[m
[32m[rank0]:eos_id=0[m
[32m[rank0]:ffn_dim_multiplier=None[m
[32m[rank0]:inter_dim=1024[m
[32m[rank0]:kv_lora_rank=512[m
[32m[rank0]:max_seq_len=2048[m
[32m[rank0]:moe_args=MoEArgs(num_experts=8,[m num_shared_experts=2, score_func='softmax', route_norm=True, route_scale=1.0, score_before_experts=False, top_k=3, use_grouped_mm=True, [31mload_balance_coeff=0.001), n_expert_groups=1, n_limited_groups=1, q_lora_rank=0, kv_lora_rank=512, qk_nope_head_dim=128, qk_rope_head_dim=64, v_head_dim=128, use_flex_attn=False, attn_mask_type='causal', original_seq_len=4096, rope_theta=10000.0, rope_factor=40, beta_fast=32, beta_slow=1, mscale=0.7)[m[32mload_balance_coeff=0.001)[m
[32m[rank0]:moe_inter_dim=256[m
[32m[rank0]:moe_intermediate_size=256[m
[32m[rank0]:mscale=0.7[m
[32m[rank0]:multiple_of=256[m
[32m[rank0]:n_dense_layers=1[m
[32m[rank0]:n_expert_groups=None[m
[32m[rank0]:n_group=2[m
[32m[rank0]:n_heads=16[m
[32m[rank0]:n_kv_heads=16[m
[32m[rank0]:n_layers=2[m
[32m[rank0]:n_limited_groups=None[m
[32m[rank0]:n_routed_experts=8[m
[32m[rank0]:n_shared_experts=2[m
[32m[rank0]:norm_eps=1e-05[m
[32m[rank0]:num_experts_per_tok=3[m
[32m[rank0]:original_seq_len=None[m
[32m[rank0]:partial_rotary_factor=4.0[m
[32m[rank0]:q_lora_rank=None[m
[32m[rank0]:qk_nope_head_dim=128[m
[32m[rank0]:qk_rope_head_dim=64[m
[32m[rank0]:rope_factor=None[m
[32m[rank0]:rope_theta=10000[m
[32m[rank0]:topk_group=1[m
[32m[rank0]:use_flex_attn=False[m
[32m[rank0]:v_head_dim=128[m
[32m[rank0]:vocab_size=2000[m
[32m[rank0]:)[m
[rank0]:[titan] TIMESTAMP - root - INFO - CUDA capacity: NVIDIA H100 80GB HBM3 with 79.44GiB memory[m
[31m[rank0]:[titan] TIMESTAMP - root - INFO - Total parameter count: dense 8,923,392, sparse 1,968,128, active 9,908,480[m
[rank0]:[titan] TIMESTAMP - root - INFO - Model Structure Parameter Breakdown:[m
[rank0]:[titan] TIMESTAMP - root - INFO - [31mDeepSeekV3Model[m[32mHFTransformerModel[m - 10,891,520 params
[rank0]:[titan] TIMESTAMP - root - INFO -   [31m(tok_embeddings):[m[32m(embed_tokens):[m Embedding - 512,000 params
[rank0]:[titan] TIMESTAMP - root - INFO -   (layers): [31mModuleDict[m[32mModuleList[m - 9,867,264 params
[rank0]:[titan] TIMESTAMP - root - INFO -     (0): [31mTransformerBlock[m[32mDeepseekV3DecoderLayer[m - 4,342,784 params
[rank0]:[titan] TIMESTAMP - root - INFO -       [31m(attention): Attention[m[32m(self_attn): DeepseekV3Attention[m - 3,555,840 params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(wq):[m[32m(q_proj):[m Linear - 786,432 params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(wkv_a):[m[32m(kv_a_proj_with_mqa):[m Linear - 147,456 params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(kv_norm): RMSNorm[m[32m(kv_a_layernorm): DeepseekV3RMSNorm[m - 512 params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(wkv_b):[m[32m(kv_b_proj):[m Linear - 2,097,152 params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(wo):[m[32m(o_proj):[m Linear - 524,288 params
[rank0]:[titan] TIMESTAMP - root - INFO -       [31m(attention_norm): RMSNorm[m[32m(mlp): DeepseekV3MLP[m - [31m256[m[32m786,432[m params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(ffn_norm): RMSNorm[m[32m(gate_proj): Linear[m - [31m256[m[32m262,144[m params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(feed_forward): FeedForward[m[32m(up_proj): Linear[m - [31m786,432[m[32m262,144[m params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(w1):[m[32m(down_proj):[m Linear - 262,144 params
[rank0]:[titan] TIMESTAMP - root - INFO -       [31m(w2): Linear[m[32m(input_layernorm): DeepseekV3RMSNorm[m - [31m262,144[m[32m256[m params
[rank0]:[titan] TIMESTAMP - root - INFO -       [31m(w3): Linear[m[32m(post_attention_layernorm): DeepseekV3RMSNorm[m - [31m262,144[m[32m256[m params
[rank0]:[titan] TIMESTAMP - root - INFO -     (1): [31mTransformerBlock[m[32mDeepseekV3DecoderLayer[m - 5,524,480 params
[rank0]:[titan] TIMESTAMP - root - INFO -       [31m(attention): Attention[m[32m(self_attn): DeepseekV3Attention[m - 3,555,840 params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(wq):[m[32m(q_proj):[m Linear - 786,432 params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(wkv_a):[m[32m(kv_a_proj_with_mqa):[m Linear - 147,456 params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(kv_norm): RMSNorm[m[32m(kv_a_layernorm): DeepseekV3RMSNorm[m - 512 params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(wkv_b):[m[32m(kv_b_proj):[m Linear - 2,097,152 params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(wo):[m[32m(o_proj):[m Linear - 524,288 params
[rank0]:[titan] TIMESTAMP - root - INFO -       [31m(attention_norm): RMSNorm[m[32m(mlp): DeepseekV3MoE[m - [31m256[m[32m1,968,128[m params
[rank0]:[titan] TIMESTAMP - root - INFO -         [31m(ffn_norm): RMSNorm[m[32m(experts): ModuleList[m - [31m256[m[32m1,572,864[m params
[rank0]:[titan] TIMESTAMP - root - INFO -           [31m(moe): MoE[m[32m(0): DeepseekV3MLP[m - [31m1,968,128[m[32m196,608[m params
[rank0]:[titan] TIMESTAMP - root - INFO -             [31m(experts): GroupedExperts[m[32m(gate_proj): Linear[m - [31m1,572,864[m[32m65,536[m params
[rank0]:[titan] TIMESTAMP - root - INFO -             [31m(router): TokenChoiceTopKRouter[m[32m(up_proj): Linear[m - [31m2,048[m[32m65,536[m params
[rank0]:[titan] TIMESTAMP - root - INFO -             [31m(gate):[m[32m(down_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -           (1): DeepseekV3MLP - 196,608 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (gate_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (up_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (down_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -           (2): DeepseekV3MLP - 196,608 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (gate_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (up_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (down_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -           (3): DeepseekV3MLP - 196,608 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (gate_proj):[m Linear - [32m65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (up_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (down_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -           (4): DeepseekV3MLP - 196,608 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (gate_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (up_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (down_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -           (5): DeepseekV3MLP - 196,608 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (gate_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (up_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (down_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -           (6): DeepseekV3MLP - 196,608 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (gate_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (up_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (down_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -           (7): DeepseekV3MLP - 196,608 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (gate_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (up_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -             (down_proj): Linear - 65,536 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -         (gate): DeepseekV3TopkRouter -[m 2,048 params
[rank0]:[titan] TIMESTAMP - root - INFO -         (shared_experts): [31mFeedForward[m[32mDeepseekV3MLP[m - 393,216 params
[rank0]:[titan] TIMESTAMP - root - INFO -           [31m(w1):[m[32m(gate_proj):[m Linear - 131,072 params
[rank0]:[titan] TIMESTAMP - root - INFO -           [31m(w2):[m[32m(up_proj):[m Linear - 131,072 params
[rank0]:[titan] TIMESTAMP - root - INFO -           [31m(w3):[m[32m(down_proj):[m Linear - 131,072 params
[rank0]:[titan] TIMESTAMP - root - INFO -       [32m(input_layernorm): DeepseekV3RMSNorm - 256 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -       (post_attention_layernorm): DeepseekV3RMSNorm - 256 params[m
[32m[rank0]:[titan] TIMESTAMP - root - INFO -[m   (norm): [31mRMSNorm[m[32mDeepseekV3RMSNorm[m - 256 params
[rank0]:[titan] TIMESTAMP - root - INFO -   [31m(output):[m[32m(lm_head):[m Linear - 512,000 params
[rank0]:[titan] TIMESTAMP - root - INFO - [34mModel [31mdeepseek_v3[m[32mdeepseek-ai/DeepSeek-V3[m debugmodel [31msize: 10,891,520 total parameters[39m
[rank0]:[titan] TIMESTAMP - root - INFO - Applied selective activation checkpointing to the model[m
[rank0]:[titan] TIMESTAMP - root - INFO - Peak FLOPS used for computing MFU: 9.890e+14[m
[rank0]:[titan] TIMESTAMP - root - INFO - CUDA memory usage for model: 0.05GiB(0.06%)[m
[rank0]:[titan] TIMESTAMP - root - INFO - Mixed precision training is handled by AMP[m
[rank0]:[titan] TIMESTAMP - root - INFO - Trainer is initialized with local batch size 8, global batch size 8, gradient accumulation steps 1, sequence length 2048, total steps 10 (warmup 2)[m
[rank0]:[titan] TIMESTAMP - root - INFO - Training starts at step 1[m
[rank0]:[titan] TIMESTAMP - root - INFO - Profiling active. Traces will be saved at [31m./outputs/profile_trace[m
[31m[rank0]:/fsx/ferdinandmom/ferdinand-hf/huggingface/torchtitan/env_torchtitan_official/lib/python3.12/site-packages/torch/nn/functional.py:2920: UserWarning: Mismatch dtype between input and weight: input dtype = c10::BFloat16, weight dtype = float, Cannot dispatch to fused implementation. (Triggered internally at /pytorch/aten/src/ATen/native/layer_norm.cpp:344.)[m
[31m[rank0]:  return torch.rms_norm(input, normalized_shape, weight, eps)[m[32m./outputs/profile_trace_hf[m
[rank0]:[titan] TIMESTAMP - root - INFO - [31mstep:  1  [32mloss:  [31m8.1381[m[32m8.1218[m  [38;2;180;60;0mgrad_norm:  [31m2.7374[m[32m2.7807[m  [38;2;54;234;195mmemory:  [31m2.14GiB(2.70%)[m[32m2.48GiB(3.13%)[m  [34mtps: [31m18,024[m[32m11,445[m  [36mtflops: [31m1.24[m[32m0.89[m  [35mmfu: [31m0.13%[39m[m[32m0.09%[39m[m
[rank0]:[titan] TIMESTAMP - root - INFO - Synchronizing and adjusting timeout for all ProcessGroups to 0:01:40[m
[rank0]:[titan] TIMESTAMP - root - INFO - [31mstep:  2  [32mloss:  [31m7.0208[m[32m6.8905[m  [38;2;180;60;0mgrad_norm:  [31m3.2615[m[32m3.2709[m  [38;2;54;234;195mmemory:  [31m2.15GiB(2.71%)[m[32m2.49GiB(3.13%)[m  [34mtps: [31m20,232[m[32m17,755[m  [36mtflops: [31m1.40[m[32m1.38[m  [35mmfu: 0.14%[39m
[rank0]:[titan] TIMESTAMP - root - INFO - [31mstep:  3  [32mloss:  [31m5.2642[m[32m5.1682[m  [38;2;180;60;0mgrad_norm:  [31m2.8735[m[32m2.8229[m  [38;2;54;234;195mmemory:  [31m2.15GiB(2.71%)[m[32m2.49GiB(3.13%)[m  [34mtps: [31m325,066[m[32m119,606[m  [36mtflops: [31m22.42[m[32m9.32[m  [35mmfu: [31m2.27%[39m[m[32m0.94%[39m[m
[rank0]:[titan] TIMESTAMP - root - INFO - [31mstep:  4  [32mloss:  [31m4.8286[m[32m4.7719[m  [38;2;180;60;0mgrad_norm:  [31m2.1885[m[32m2.2433[m  [38;2;54;234;195mmemory:  [31m2.15GiB(2.71%)[m[32m2.51GiB(3.15%)[m  [34mtps: [31m345,536[m[32m135,937[m  [36mtflops: [31m23.83[m[32m10.59[m  [35mmfu: [31m2.41%[39m[m[32m1.07%[39m[m
[rank0]:[titan] TIMESTAMP - root - INFO - [31mstep:  5  [32mloss:  [31m4.4370[m[32m4.3827[m  [38;2;180;60;0mgrad_norm:  [31m2.3053[m[32m2.3779[m  [38;2;54;234;195mmemory:  [31m2.15GiB(2.71%)[m[32m2.51GiB(3.15%)[m  [34mtps: [31m296,009[m[32m133,266[m  [36mtflops: [31m20.41[m[32m10.39[m  [35mmfu: [31m2.06%[39m[m[32m1.05%[39m[m
[rank0]:[titan] TIMESTAMP - root - INFO - Dumping profiler traces at step 5[m
[rank0]:[titan] TIMESTAMP - root - INFO - Finished dumping profiler traces in [31m0.03[m[32m0.05[m seconds
[rank0]:[titan] TIMESTAMP - root - INFO - [31mstep:  6  [32mloss:  [31m4.3063[m[32m4.2368[m  [38;2;180;60;0mgrad_norm:  [31m2.2445[m[32m2.2557[m  [38;2;54;234;195mmemory:  [31m2.15GiB(2.71%)[m[32m2.71GiB(3.41%)[m  [34mtps: [31m136,065[m[32m66,465[m  [36mtflops: [31m9.38[m[32m5.18[m  [35mmfu: [31m0.95%[39m[m[32m0.52%[39m[m
[rank0]:[titan] TIMESTAMP - root - INFO - [31mstep:  7  [32mloss:  [31m4.1253[m[32m4.0403[m  [38;2;180;60;0mgrad_norm:  [31m1.9626[m[32m1.9132[m  [38;2;54;234;195mmemory:  [31m2.15GiB(2.71%)[m[32m2.71GiB(3.41%)[m  [34mtps: [31m299,863[m[32m131,077[m  [36mtflops: [31m20.68[m[32m10.22[m  [35mmfu: [31m2.09%[39m[m[32m1.03%[39m[m
[rank0]:[titan] TIMESTAMP - root - INFO - [31mstep:  8  [32mloss:  [31m4.0645[m[32m3.9796[m  [38;2;180;60;0mgrad_norm:  [31m1.8299[m[32m1.8154[m  [38;2;54;234;195mmemory:  [31m2.15GiB(2.71%)[m[32m2.71GiB(3.41%)[m  [34mtps: [31m343,855[m[32m147,955[m  [36mtflops: [31m23.71[m[32m11.53[m  [35mmfu: [31m2.40%[39m[m[32m1.17%[39m[m
[rank0]:[titan] TIMESTAMP - root - INFO - [31mstep:  9  [32mloss:  [31m4.4758[m[32m4.4010[m  [38;2;180;60;0mgrad_norm:  [31m1.4743[m[32m1.4965[m  [38;2;54;234;195mmemory:  [31m2.15GiB(2.71%)[m[32m2.71GiB(3.41%)[m  [34mtps: [31m346,707[m[32m139,416[m  [36mtflops: [31m23.91[m[32m10.87[m  [35mmfu: [31m2.42%[39m[m[32m1.10%[39m[m
[rank0]:[titan] TIMESTAMP - root - INFO - [31mstep: 10  [32mloss:  [31m3.9483[m[32m3.8448[m  [38;2;180;60;0mgrad_norm:  [31m1.6240[m[32m1.6185[m  [38;2;54;234;195mmemory:  [31m2.15GiB(2.71%)[m[32m2.71GiB(3.41%)[m  [34mtps: [31m303,029[m[32m139,581[m  [36mtflops: [31m20.90[m[32m10.88[m  [35mmfu: [31m2.11%[39m[m[32m1.10%[39m[m
[rank0]:[titan] TIMESTAMP - root - INFO - Dumping profiler traces at step 10[m
[rank0]:[titan] TIMESTAMP - root - INFO - Finished dumping profiler traces in [31m0.02[m[32m0.04[m seconds
[rank0]:[titan] TIMESTAMP - root - INFO - Sleeping 2 seconds for other ranks to complete[m
[rank0]:[titan] TIMESTAMP - root - INFO - Training completed[m
[rank0]:[titan] TIMESTAMP - root - INFO - Process group destroyed[m
